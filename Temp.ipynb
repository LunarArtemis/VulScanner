{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Bidirectional, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class BLSTM:\n",
    "    def __init__(self, data_path, name=\"graph2vec_BLSTM\", batch_size=64, epochs=20):\n",
    "        self.name = name\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "\n",
    "        # Load and preprocess data\n",
    "        self._load_data(data_path)\n",
    "\n",
    "        # Build and compile model\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _load_data(self, data_path):\n",
    "        data = pd.read_csv(data_path)  # Load graph2vec features\n",
    "        print(\"Dataset Preview:\")\n",
    "        print(data.head())\n",
    "\n",
    "        indices = data['type'].values\n",
    "        y = data.iloc[:, 4]\n",
    "        y_labels = y.iloc[indices]\n",
    "        \n",
    "        X = data.drop(columns=\"type\")\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y_labels, test_size=0.2, random_state=42)\n",
    "        print(\"Train data shape:\", self.X_train.shape)\n",
    "        print(\"Test data shape:\", self.X_test.shape)\n",
    "        \n",
    "\n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=(self.X_train.shape[1], self.X_train.shape[2])))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Bidirectional(LSTM(64)))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        model.compile(optimizer=Adam(learning_rate=0.02), loss='binary_crossentropy', metrics=['accuracy', 'AUC'])\n",
    "        return model\n",
    "\n",
    "    def train(self):\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "        model_checkpoint = ModelCheckpoint(self.name + \"_best_model.weights.keras\", save_best_only=True, monitor='val_loss')\n",
    "\n",
    "        history = self.model.fit(\n",
    "            self.X_train, self.y_train,\n",
    "            validation_data=(self.X_test, self.y_test),\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            callbacks=[early_stopping, model_checkpoint]\n",
    "        )\n",
    "\n",
    "        self._plot_learning_curve(history)\n",
    "\n",
    "    def _plot_learning_curve(self, history):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "        plt.ylim(0, 1)\n",
    "        plt.title('Model Accuracy')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(history.history['loss'], label='Train Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.ylim(0, 2)\n",
    "        plt.title('Model Loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "    def test(self):\n",
    "        self.model.load_weights(self.name + \"_best_model.weights.keras\")\n",
    "        results = self.model.evaluate(self.X_test, self.y_test)\n",
    "        print(\"Test loss:\", results[0])\n",
    "        print(\"Test accuracy:\", results[1])\n",
    "        print(\"Test AUC:\", results[2])\n",
    "\n",
    "# Usage:\n",
    "# blstm = BLSTM(\"graph2vec_features.csv\")\n",
    "# blstm.train()\n",
    "# blstm.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
