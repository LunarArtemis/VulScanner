{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1850f34a66d041f4a99e217b57625136",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": []
   },
   "source": [
    "# NEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "41304c0130a140f384b7dae8836ad474",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_context_id": "f00cc075-af73-4bbd-9865-2a41d25f2f76",
    "execution_millis": 2279,
    "execution_start": 1728409485637,
    "source_hash": "e7755d61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Project\\VulScanner\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Bidirectional, LeakyReLU\n",
    "from keras.optimizers import Adamax\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "import os\n",
    "\n",
    "current_path = os.getcwd()\n",
    "print(current_path)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "cb715dd09ce844cbae0dab2f977db87e",
    "deepnote_cell_type": "code",
    "execution_context_id": "f00cc075-af73-4bbd-9865-2a41d25f2f76",
    "execution_millis": 127,
    "execution_start": 1728409487965,
    "source_hash": "b1d13704"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(current_path + '/Source2Slice/processed_gadgets_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "4795280390e64af08849d93550761ebc",
    "deepnote_cell_type": "code",
    "deepnote_table_loading": false,
    "deepnote_table_state": {
     "conditionalFilters": [],
     "filters": [],
     "pageIndex": 0,
     "pageSize": 100,
     "sortBy": [],
     "wrappedTextColumnIds": []
    },
    "execution_context_id": "f00cc075-af73-4bbd-9865-2a41d25f2f76",
    "execution_millis": 1,
    "execution_start": 1728409488145,
    "source_hash": "7811243c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gadget</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>const app = express();\\napp.get('/file/:filePa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\napp.get('/read/:filePath', (req, res) =&gt; {\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\napp.get('/config', (req, res) =&gt; {\\n    cons...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\napp.get('/config', (req, res) =&gt; {\\n    cons...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\napp.get('/config', (req, res) =&gt; {\\n    cons...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              gadget  label\n",
       "0  const app = express();\\napp.get('/file/:filePa...      1\n",
       "1  \\napp.get('/read/:filePath', (req, res) => {\\n...      0\n",
       "2  \\napp.get('/config', (req, res) => {\\n    cons...      1\n",
       "3  \\napp.get('/config', (req, res) => {\\n    cons...      1\n",
       "4  \\napp.get('/config', (req, res) => {\\n    cons...      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "0cbc4ada8c4b4797858c5a9f8d5d1c66",
    "deepnote_cell_type": "code",
    "deepnote_table_loading": false,
    "deepnote_table_state": {
     "conditionalFilters": [],
     "filters": [],
     "pageIndex": 0,
     "pageSize": 100,
     "sortBy": [],
     "wrappedTextColumnIds": []
    },
    "execution_context_id": "f00cc075-af73-4bbd-9865-2a41d25f2f76",
    "execution_millis": 1,
    "execution_start": 1728409488193,
    "source_hash": "ed0181b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48 entries, 0 to 47\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   code    48 non-null     object\n",
      " 1   label   48 non-null     int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 900.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# Cleaning data \n",
    "df.dropna(inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "#df.columns = ['code', 'label']\n",
    "# rename the columns to code and label\n",
    "df.columns = ['code', 'label']\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "3e93128be91748489897c2199303107b",
    "deepnote_cell_type": "code",
    "execution_context_id": "f00cc075-af73-4bbd-9865-2a41d25f2f76",
    "execution_millis": 1,
    "execution_start": 1728409488253,
    "source_hash": "c209ffdd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Bidirectional, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "class BLSTM:\n",
    "    def __init__(self, data, name=\"\", batch_size=64, epochs=20, max_length=128):\n",
    "        self.data = data\n",
    "        self.name = name\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.max_length = max_length\n",
    "\n",
    "        # Load CodeBERT tokenizer and embedding model\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "        self.embedding_model = AutoModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "\n",
    "        # Preprocess data\n",
    "        self._preprocess_data()\n",
    "\n",
    "        # Build and compile model\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _preprocess_data(self):\n",
    "        self.data['label'] = self.data['label'].astype(int)\n",
    "        \n",
    "        embeddings = []\n",
    "        for code in self.data['code']:\n",
    "            inputs = self.tokenizer(code, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=self.max_length)\n",
    "            with torch.no_grad():\n",
    "                outputs = self.embedding_model(**inputs)\n",
    "            embedding = outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "            embeddings.append(embedding)\n",
    "\n",
    "        self.X = np.array(embeddings).squeeze()\n",
    "        self.y = self.data['label'].values\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.X, self.y, test_size=0.2, random_state=12\n",
    "        )\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=(self.X_train.shape[1], 1)))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Bidirectional(LSTM(64)))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "        model.compile(optimizer=Adam(learning_rate=0.02), loss='binary_crossentropy', metrics=['accuracy', 'AUC'])\n",
    "    \n",
    "        return model\n",
    "\n",
    "    def train(self):\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "        model_checkpoint = ModelCheckpoint(self.name + \"_best_model.weights.keras\", save_best_only=True, monitor='val_loss')\n",
    "        \n",
    "        history = self.model.fit(\n",
    "            self.X_train, self.y_train,\n",
    "            validation_data=(self.X_test, self.y_test),\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            callbacks=[early_stopping, model_checkpoint]\n",
    "        )\n",
    "\n",
    "        self._plot_learning_curve(history)\n",
    "\n",
    "    def _plot_learning_curve(self, history):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "        plt.ylim(0, 1)  # Set y-axis limit for accuracy\n",
    "        plt.title('Model Accuracy')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(history.history['loss'], label='Train Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.ylim(0, 2)  # Set y-axis limit for loss\n",
    "        plt.title('Model Loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "    def test(self):\n",
    "        self.model.load_weights(self.name + \"_best_model.weights.keras\")\n",
    "        results = self.model.evaluate(self.X_test, self.y_test)\n",
    "        print(\"Test loss:\", results[0])\n",
    "        print(\"Test accuracy:\", results[1])\n",
    "        print(\"Test AUC:\", results[2])\n",
    "\n",
    "    def predict_code(self, file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            code_lines = f.readlines()\n",
    "\n",
    "        vulnerable_lines = []\n",
    "        predictions = []\n",
    "\n",
    "        for idx, line in enumerate(code_lines):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            inputs = self.tokenizer([line], return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=self.max_length)\n",
    "            with torch.no_grad():\n",
    "                outputs = self.embedding_model(**inputs)\n",
    "            embeddings = outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "            embeddings = np.expand_dims(embeddings, axis=1)\n",
    "\n",
    "            prediction = self.model.predict(embeddings)\n",
    "            predicted_class = 1 if prediction > 0.5 else 0\n",
    "\n",
    "            predictions.append(predicted_class)\n",
    "            if predicted_class == 1:\n",
    "                vulnerable_lines.append(idx)\n",
    "\n",
    "        result = \"Vulnerable\" if 1 in predictions else \"Non-Vulnerable\"\n",
    "        vulnerable_code_lines = [f\"{idx + 1}: {code_lines[i].strip()}\" for i in vulnerable_lines]\n",
    "\n",
    "        return result, vulnerable_code_lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "ba8471471e8545858d1fcefe68dfe185",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_context_id": "f00cc075-af73-4bbd-9865-2a41d25f2f76",
    "execution_millis": 22226,
    "execution_start": 1728409488305,
    "source_hash": "2c1eaab3"
   },
   "outputs": [],
   "source": [
    "blstm = BLSTM(df, name=\"codebert_blstm_model\", batch_size=10, epochs=100)\n",
    "blstm.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "cell_id": "ef042e49f07a45f8a24de5fe1c02b22b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_context_id": "f00cc075-af73-4bbd-9865-2a41d25f2f76",
    "execution_millis": 1676,
    "execution_start": 1728409511245,
    "source_hash": "5ddf9236"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - AUC: 0.5000 - accuracy: 0.5862 - loss: 0.6794\n",
      "Test loss: 0.6794040203094482\n",
      "Test accuracy: 0.5862069129943848\n",
      "Test AUC: 0.5\n"
     ]
    }
   ],
   "source": [
    "blstm.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCodeClassifier:\n",
    "    def __init__(self, data, model_type=\"logistic\"):\n",
    "        self.data = data\n",
    "        self.model_type = model_type\n",
    "\n",
    "        # Load CodeBERT tokenizer and model\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "        self.embedding_model = AutoModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "\n",
    "        # Preprocess data and extract embeddings\n",
    "        self._preprocess_data()\n",
    "\n",
    "        # Choose classifier\n",
    "        self.model = self._choose_classifier()\n",
    "\n",
    "    def _preprocess_data(self):\n",
    "        # Tokenize code snippets and get embeddings\n",
    "        embeddings = []\n",
    "        for code in self.data['code']:\n",
    "            inputs = self.tokenizer(code, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "            outputs = self.embedding_model(**inputs)\n",
    "            embedding = outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "            embeddings.append(embedding)\n",
    "\n",
    "        self.X = np.array(embeddings).squeeze()\n",
    "        self.y = self.data['label'].values\n",
    "\n",
    "        # Split dataset\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.X, self.y, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "    def _choose_classifier(self):\n",
    "        if self.model_type == \"logistic\":\n",
    "            return LogisticRegression()\n",
    "        elif self.model_type == \"svm\":\n",
    "            return SVC(probability=True)\n",
    "        elif self.model_type == \"random_forest\":\n",
    "            return RandomForestClassifier()\n",
    "\n",
    "    def train(self):\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "\n",
    "    def test(self):\n",
    "        y_pred = self.model.predict(self.X_test)\n",
    "        y_pred_proba = self.model.predict_proba(self.X_test)[:, 1]\n",
    "\n",
    "        accuracy = accuracy_score(self.y_test, y_pred)\n",
    "        auc = roc_auc_score(self.y_test, y_pred_proba)\n",
    "\n",
    "        print(f\"Test accuracy: {accuracy}\")\n",
    "        print(f\"Test AUC: {auc}\")\n",
    "\n",
    "    def predict_code(self, file_path):\n",
    "        # Read the entire source code from the file\n",
    "        with open(file_path, 'r') as f:\n",
    "            code = f.read().strip()\n",
    "    \n",
    "        # Tokenize and embed the entire code\n",
    "        inputs = self.tokenizer(code, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        outputs = self.embedding_model(**inputs)\n",
    "    \n",
    "        # Take mean of the embeddings along the sequence length to get a single 2D vector\n",
    "        embedding = outputs.last_hidden_state.mean(dim=1).detach().numpy().squeeze()\n",
    "    \n",
    "        # Predict the label (vulnerable or non-vulnerable) for the entire file\n",
    "        prediction = self.model.predict(np.array([embedding]))[0]  # Predict expects a 2D array\n",
    "    \n",
    "        # Interpret the prediction result\n",
    "        result = \"Vulnerable\" if prediction == 1 else \"Non-Vulnerable\"\n",
    "    \n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage:\n",
    "# Assuming 'data' is your pandas DataFrame with 'code' and 'label' columns\n",
    "\n",
    "simple_classifier = SimpleCodeClassifier(df, model_type=\"logistic\")\n",
    "simple_classifier.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8275862068965517\n",
      "Test AUC: 0.880952380952381\n"
     ]
    }
   ],
   "source": [
    "simple_classifier.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d36a91c5465842d2b1c9d2598a42f08e",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": []
   },
   "source": [
    "# Predict With BLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "The predicted label for the source code is: ('Vulnerable', [\"13: const fs = require('fs');\", \"13: const path = require('path');\", \"13: const filePath = path.join(__dirname, 'file.txt');\", '13: async function readFile() {', '13: try {', '13: await fs.promises.access(filePath, fs.constants.F_OK);', \"13: const data = await fs.promises.readFile(filePath, 'utf8');\", '13: console.log(data);', '13: } catch (err) {', \"13: console.error('Error reading the file:', err.message);\", '13: }', '13: }', '13: readFile();'])\n"
     ]
    }
   ],
   "source": [
    "# Predicting vulnerability for the whole file\n",
    "prediction = blstm.predict_code(current_path + '/SourceCode/nonvuln.js')\n",
    "\n",
    "print(f\"The predicted label for the source code is: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "The predicted label for the source code is: ('Vulnerable', ['15: // Function to calculate the factorial of a number', '15: function factorial(n) {', '15: if (n < 0) {', '15: return \"Factorial is not defined for negative numbers\";', '15: } else if (n === 0 || n === 1) {', '15: return 1; // Base case', '15: } else {', '15: return n * factorial(n - 1); // Recursive case', '15: }', '15: }', '15: // Example usage', '15: const number = 5;', '15: const result = factorial(number);', '15: console.log(`The factorial of ${number} is ${result}`);'])\n"
     ]
    }
   ],
   "source": [
    "# Predicting vulnerability for the whole file\n",
    "prediction = blstm.predict_code(current_path + '/SourceCode/nonvuln2.js')\n",
    "\n",
    "print(f\"The predicted label for the source code is: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "The predicted label for the source code is: ('Vulnerable', [\"21: const express = require('express');\", \"21: const fs = require('fs');\", \"21: const path = require('path');\", '21: const app = express();', '21: const port = 3000;', \"21: app.get('/file', (req, res) => {\", '21: const fileName = req.query.file;', '21: const filePath = path.join(__dirname, fileName);', \"21: fs.readFile(filePath, 'utf8', (err, data) => {\", '21: if (err) {', \"21: return res.status(404).send('File not found!');\", '21: }', '21: res.send(data);', '21: });', '21: });', '21: app.listen(port, () => {', '21: console.log(`Server running at http://localhost:${port}`);', '21: });'])\n"
     ]
    }
   ],
   "source": [
    "# Predicting vulnerability for the whole file\n",
    "prediction = blstm.predict_code(current_path + '/SourceCode/vuln2.js')\n",
    "\n",
    "print(f\"The predicted label for the source code is: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "The predicted label for the source code is: ('Vulnerable', [\"21: const express = require('express');\", \"21: const fs = require('fs');\", \"21: const path = require('path');\", '21: const app = express();', '21: const port = 3000;', \"21: app.get('/file', (req, res) => {\", '21: const fileName = req.query.file;', '21: const filePath = path.join(__dirname, fileName);', \"21: fs.readFile(filePath, 'utf8', (err, data) => {\", '21: if (err) {', \"21: return res.status(404).send('File not found!');\", '21: }', '21: res.send(data);', '21: });', '21: });', '21: app.listen(port, () => {', '21: console.log(`Server running at http://localhost:${port}`);', '21: });'])\n"
     ]
    }
   ],
   "source": [
    "# Predicting vulnerability for the whole file\n",
    "prediction = blstm.predict_code(current_path + '/SourceCode/vuln2.js')\n",
    "\n",
    "print(f\"The predicted label for the source code is: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "The predicted label for the source code is: Vulnerable\n",
      "Vulnerable lines found:\n",
      "13: const fs = require('fs');\n",
      "13: const path = require('path');\n",
      "13: const filePath = path.join(__dirname, 'file.txt');\n",
      "13: async function readFile() {\n",
      "13: try {\n",
      "13: await fs.promises.access(filePath, fs.constants.F_OK);\n",
      "13: const data = await fs.promises.readFile(filePath, 'utf8');\n",
      "13: console.log(data);\n",
      "13: } catch (err) {\n",
      "13: console.error('Error reading the file:', err.message);\n",
      "13: }\n",
      "13: }\n",
      "13: readFile();\n"
     ]
    }
   ],
   "source": [
    "prediction, vulnerable_lines = blstm.predict_code(current_path + '/SourceCode/nonvuln.js')\n",
    "\n",
    "print(f\"The predicted label for the source code is: {prediction}\")\n",
    "print(f\"Vulnerable lines found:\")\n",
    "for line in vulnerable_lines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict with Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for the file: Vulnerable\n"
     ]
    }
   ],
   "source": [
    "file_path = current_path + '/SourceCode/nonvuln.js'  # Replace with your file path\n",
    "result = simple_classifier.predict_code(file_path)\n",
    "\n",
    "# Print the prediction result\n",
    "print(\"Prediction for the file:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for the file: Non-Vulnerable\n"
     ]
    }
   ],
   "source": [
    "file_path = current_path + '/SourceCode/vuln.js'  # Replace with your file path\n",
    "result = simple_classifier.predict_code(file_path)\n",
    "\n",
    "# Print the prediction result\n",
    "print(\"Prediction for the file:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for the file: Vulnerable\n"
     ]
    }
   ],
   "source": [
    "file_path = current_path + '/SourceCode/vuln2.js'  # Replace with your file path\n",
    "result = simple_classifier.predict_code(file_path)\n",
    "\n",
    "# Print the prediction result\n",
    "print(\"Prediction for the file:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for the file: Vulnerable\n"
     ]
    }
   ],
   "source": [
    "file_path = current_path + '/SourceCode/nonvuln2.js'  # Replace with your file path\n",
    "result = simple_classifier.predict_code(file_path)\n",
    "\n",
    "# Print the prediction result\n",
    "print(\"Prediction for the file:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=f5982bd9-4186-4df6-a44f-a0eeec8cd72d' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "8bb24c6b01d34bcab6b76577d97e6094",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
