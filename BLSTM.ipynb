{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dropout, BatchNormalization, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class BLSTM:\n",
    "    def __init__(self, data_path, name=\"graph2vec_BLSTM\", batch_size=32, epochs=50):\n",
    "        self.name = name\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "\n",
    "        # Load and preprocess data\n",
    "        self._load_data(data_path)\n",
    "\n",
    "        # Reshape data for LSTM\n",
    "        self._reshape_data()\n",
    "\n",
    "        # Build and compile model\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _load_data(self, data_path):\n",
    "        \"\"\"Load and preprocess the dataset.\"\"\"\n",
    "        data = pd.read_csv(data_path)  # Load graph2vec features\n",
    "        print(\"Dataset Preview:\")\n",
    "        print(data.head())\n",
    "\n",
    "        # Check for missing values\n",
    "        if data.isnull().any().any():\n",
    "            raise ValueError(\"Dataset contains missing values. Please handle them before proceeding.\")\n",
    "\n",
    "        # Encode labels (if they are not binary)\n",
    "        self.y = data['type'].values\n",
    "        if len(np.unique(self.y)) > 2:  # If multiclass, encode labels\n",
    "            self.y = LabelEncoder().fit_transform(self.y)\n",
    "        else:  # Ensure binary labels are 0 and 1\n",
    "            self.y = (self.y > 0).astype(int)\n",
    "\n",
    "        # Scale features\n",
    "        self.X = data.drop(columns=\"type\").values\n",
    "        self.X = StandardScaler().fit_transform(self.X)  # Normalize features\n",
    "\n",
    "        # Split into train and test sets\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.X, self.y, test_size=0.2, random_state=42\n",
    "        )\n",
    "        print(\"Train data shape:\", self.X_train.shape)\n",
    "        print(\"Test data shape:\", self.X_test.shape)\n",
    "        print(\"Unique labels in y_train:\", np.unique(self.y_train))\n",
    "        print(\"Unique labels in y_test:\", np.unique(self.y_test))\n",
    "        print(\"X_train mean:\", np.mean(self.X_train))\n",
    "        print(\"X_train std:\", np.std(self.X_train))\n",
    "\n",
    "    def _reshape_data(self):\n",
    "        \"\"\"Reshape data into 3D format for LSTM.\"\"\"\n",
    "        self.X_train = np.reshape(self.X_train, (self.X_train.shape[0], 1, self.X_train.shape[1]))\n",
    "        self.X_test = np.reshape(self.X_test, (self.X_test.shape[0], 1, self.X_test.shape[1]))\n",
    "        print(\"Reshaped train data shape:\", self.X_train.shape)\n",
    "        print(\"Reshaped test data shape:\", self.X_test.shape)\n",
    "\n",
    "    def _build_model(self):\n",
    "        \"\"\"Build the BLSTM model.\"\"\"\n",
    "        model = Sequential()\n",
    "        model.add(Bidirectional(LSTM(64, return_sequences=True), input_shape=(self.X_train.shape[1], self.X_train.shape[2])))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Bidirectional(LSTM(32)))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))  # Sigmoid for binary classification\n",
    "\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy', 'AUC'])\n",
    "        return model\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Train the model.\"\"\"\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "        model_checkpoint = ModelCheckpoint(self.name + \"_best_model.weights.keras\", save_best_only=True, monitor='val_loss')\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n",
    "\n",
    "        history = self.model.fit(\n",
    "            self.X_train, self.y_train,\n",
    "            validation_data=(self.X_test, self.y_test),\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            callbacks=[early_stopping, model_checkpoint, reduce_lr]\n",
    "        )\n",
    "\n",
    "        self._plot_learning_curve(history)\n",
    "\n",
    "    def _plot_learning_curve(self, history):\n",
    "        \"\"\"Plot the learning curve.\"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "        plt.ylim(0, 1)\n",
    "        plt.title('Model Accuracy')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(history.history['loss'], label='Train Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.ylim(0, 2)\n",
    "        plt.title('Model Loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "    def test(self):\n",
    "        \"\"\"Evaluate the model on the test set.\"\"\"\n",
    "        try:\n",
    "            self.model.load_weights(self.name + \"_best_model.weights.keras\")\n",
    "            print(\"Model weights loaded successfully.\")\n",
    "        except Exception as e:\n",
    "            print(\"Error loading model weights:\", e)\n",
    "            return\n",
    "\n",
    "        results = self.model.evaluate(self.X_test, self.y_test)\n",
    "        print(\"Test loss:\", results[0])\n",
    "        print(\"Test accuracy:\", results[1])\n",
    "        print(\"Test AUC:\", results[2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preview:\n",
      "   type       x_0       x_1       x_2       x_3       x_4       x_5       x_6  \\\n",
      "0     0 -0.086220 -0.183489 -0.311828  0.210561 -0.011794  0.046493 -0.247115   \n",
      "1     1  0.050206 -0.533095 -0.311225  0.058918 -0.018652 -0.024216 -0.350888   \n",
      "2    10 -0.023950 -0.167754 -0.200610  0.141800 -0.017827 -0.013925 -0.161392   \n",
      "3   100 -0.008526 -0.158457 -0.380494  0.172831  0.048501 -0.012732 -0.286329   \n",
      "4  1000  0.005788 -0.437232 -0.307672  0.062768 -0.005194 -0.015667 -0.310069   \n",
      "\n",
      "        x_7       x_8  ...     x_118     x_119     x_120     x_121     x_122  \\\n",
      "0  0.002444 -0.054876  ...  0.136654  0.208798  0.118810  0.194054  0.098417   \n",
      "1 -0.090321  0.005125  ...  0.236584  0.052393 -0.022136  0.186589  0.007961   \n",
      "2 -0.095699  0.004724  ...  0.096194  0.076208  0.018431  0.087224  0.073983   \n",
      "3 -0.010031 -0.268125  ...  0.191623  0.287033 -0.020448  0.148487  0.040430   \n",
      "4 -0.057550 -0.023266  ...  0.232327  0.029678 -0.008981  0.134089  0.028003   \n",
      "\n",
      "      x_123     x_124     x_125     x_126     x_127  \n",
      "0 -0.000896 -0.060261  0.012516  0.089105 -0.105244  \n",
      "1 -0.023393  0.154599 -0.031407 -0.102472 -0.181720  \n",
      "2 -0.024665 -0.001303 -0.029866  0.062740 -0.076197  \n",
      "3 -0.068902 -0.027892  0.025348  0.106796 -0.069266  \n",
      "4 -0.011975  0.156055 -0.036535 -0.023201 -0.182217  \n",
      "\n",
      "[5 rows x 129 columns]\n",
      "Train data shape: (4200, 128)\n",
      "Test data shape: (1050, 128)\n",
      "Unique labels in y_train: [   0    1    2 ... 5247 5248 5249]\n",
      "Unique labels in y_test: [   4    9   19 ... 5231 5232 5237]\n",
      "X_train mean: 6.706585610316974e-05\n",
      "X_train std: 1.000924033592686\n",
      "Reshaped train data shape: (4200, 1, 128)\n",
      "Reshaped test data shape: (1050, 1, 128)\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - AUC: 0.0078 - accuracy: 3.3934e-04 - loss: -1238.5500 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -5240.9629 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.2353 - accuracy: 1.1889e-04 - loss: -8048.7964 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -19866.0762 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - AUC: 0.1904 - accuracy: 1.7835e-04 - loss: -27101.5977 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -51406.6758 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - AUC: 0.2883 - accuracy: 2.8617e-04 - loss: -63554.2852 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -103653.9609 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.4017 - accuracy: 1.4674e-04 - loss: -116811.1719 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -176436.1719 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.3242 - accuracy: 3.9838e-04 - loss: -187566.4375 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -222286.3281 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.2574 - accuracy: 1.3709e-04 - loss: -276819.7812 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -307611.5000 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.3251 - accuracy: 1.4348e-04 - loss: -377407.6250 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -418962.4688 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.0841 - accuracy: 9.0028e-06 - loss: -506027.6562 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -521354.2500 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.0272 - accuracy: 5.9739e-04 - loss: -653661.7500 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -682936.1875 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.2431 - accuracy: 4.6437e-04 - loss: -799347.3750 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -934337.8125 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.0333 - accuracy: 2.8617e-04 - loss: -946850.1875 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -828982.0000 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.3144 - accuracy: 5.2159e-04 - loss: -1138077.3750 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -1278959.7500 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.5293 - accuracy: 2.1996e-04 - loss: -1355893.7500 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -1317615.3750 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.1983 - accuracy: 1.1746e-04 - loss: -1545766.2500 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -1406804.6250 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.1412 - accuracy: 3.8168e-05 - loss: -1785649.5000 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -1720577.1250 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.1556 - accuracy: 0.0000e+00 - loss: -2032655.5000 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -1958571.1250 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.1009 - accuracy: 2.4106e-05 - loss: -2333334.0000 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -2316770.0000 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.6334 - accuracy: 3.1010e-04 - loss: -2526010.7500 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -2298281.5000 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.0161 - accuracy: 0.0000e+00 - loss: -2842064.2500 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -2673692.5000 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.4188 - accuracy: 1.4026e-04 - loss: -3167687.0000 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -2716691.2500 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.1610 - accuracy: 1.8155e-04 - loss: -3457306.7500 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -3069290.2500 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.3639 - accuracy: 2.5816e-04 - loss: -3730944.0000 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -3280666.5000 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.7492 - accuracy: 7.4279e-04 - loss: -4174604.7500 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -3545609.7500 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.7300 - accuracy: 3.5475e-04 - loss: -4492515.0000 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -3677653.7500 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.5875 - accuracy: 3.0462e-04 - loss: -4906348.0000 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -4199157.5000 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.7981 - accuracy: 6.4995e-04 - loss: -5225626.0000 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -4250169.0000 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.3770 - accuracy: 0.0000e+00 - loss: -5580035.0000 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -4619370.0000 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.4480 - accuracy: 1.5341e-04 - loss: -5939918.5000 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -4974318.5000 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.7545 - accuracy: 4.1115e-04 - loss: -6359255.5000 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -4820322.0000 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.5648 - accuracy: 2.1932e-04 - loss: -6677605.0000 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -5343532.5000 - learning_rate: 0.0010\n",
      "Epoch 32/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.6146 - accuracy: 4.8608e-04 - loss: -7081256.0000 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -6157402.5000 - learning_rate: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.5436 - accuracy: 2.0626e-04 - loss: -7542851.0000 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -5918594.5000 - learning_rate: 0.0010\n",
      "Epoch 34/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.0140 - accuracy: 1.9747e-04 - loss: -8003727.0000 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -6947074.0000 - learning_rate: 0.0010\n",
      "Epoch 35/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.3801 - accuracy: 7.3870e-05 - loss: -8682916.0000 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -6634469.5000 - learning_rate: 0.0010\n",
      "Epoch 36/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.2784 - accuracy: 1.9970e-04 - loss: -8950843.0000 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -7019349.5000 - learning_rate: 0.0010\n",
      "Epoch 37/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.7061 - accuracy: 3.3199e-04 - loss: -9574232.0000 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -7507051.0000 - learning_rate: 0.0010\n",
      "Epoch 38/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.0765 - accuracy: 1.3336e-04 - loss: -9932425.0000 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -8285769.0000 - learning_rate: 0.0010\n",
      "Epoch 39/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.1610 - accuracy: 0.0000e+00 - loss: -10378741.0000 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -8240435.0000 - learning_rate: 0.0010\n",
      "Epoch 40/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.5425 - accuracy: 2.0626e-04 - loss: -10938782.0000 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -8221077.5000 - learning_rate: 0.0010\n",
      "Epoch 41/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.0348 - accuracy: 7.5752e-05 - loss: -11448075.0000 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -8876062.0000 - learning_rate: 0.0010\n",
      "Epoch 42/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.3691 - accuracy: 1.1889e-04 - loss: -12002439.0000 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -9076900.0000 - learning_rate: 0.0010\n",
      "Epoch 43/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.7371 - accuracy: 3.7124e-04 - loss: -12436582.0000 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -9394525.0000 - learning_rate: 0.0010\n",
      "Epoch 44/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.5297 - accuracy: 1.9794e-04 - loss: -13175091.0000 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -10353488.0000 - learning_rate: 0.0010\n",
      "Epoch 45/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.4869 - accuracy: 2.7662e-04 - loss: -13612185.0000 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -10684719.0000 - learning_rate: 0.0010\n",
      "Epoch 46/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.9096 - accuracy: 0.0013 - loss: -14315784.0000 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -11440148.0000 - learning_rate: 0.0010\n",
      "Epoch 47/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.6605 - accuracy: 2.9219e-04 - loss: -14788909.0000 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -11627348.0000 - learning_rate: 0.0010\n",
      "Epoch 48/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.2642 - accuracy: 7.8740e-05 - loss: -15337206.0000 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -11911260.0000 - learning_rate: 0.0010\n",
      "Epoch 49/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.6746 - accuracy: 3.0472e-04 - loss: -16034272.0000 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -12128660.0000 - learning_rate: 0.0010\n",
      "Epoch 50/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.7379 - accuracy: 3.7124e-04 - loss: -16507372.0000 - val_AUC: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: -12949246.0000 - learning_rate: 0.0010\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'IPython.core.pylabtools'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m blstm \u001b[38;5;241m=\u001b[39m BLSTM(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgraph2vec/features/embledding_cwe_469.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mblstm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 95\u001b[0m, in \u001b[0;36mBLSTM.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m reduce_lr \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m)\n\u001b[1;32m     87\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train,\n\u001b[1;32m     89\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_test, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_test),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     92\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[early_stopping, model_checkpoint, reduce_lr]\n\u001b[1;32m     93\u001b[0m )\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_learning_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 99\u001b[0m, in \u001b[0;36mBLSTM._plot_learning_curve\u001b[0;34m(self, history)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_plot_learning_curve\u001b[39m(\u001b[38;5;28mself\u001b[39m, history):\n\u001b[1;32m     98\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Plot the learning curve.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m     \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfigsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    101\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/matplotlib/pyplot.py:1042\u001b[0m, in \u001b[0;36mfigure\u001b[0;34m(num, figsize, dpi, facecolor, edgecolor, frameon, FigureClass, clear, **kwargs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(allnums) \u001b[38;5;241m==\u001b[39m max_open_warning \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1033\u001b[0m     _api\u001b[38;5;241m.\u001b[39mwarn_external(\n\u001b[1;32m   1034\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMore than \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_open_warning\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m figures have been opened. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1035\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFigures created through the pyplot interface \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsider using `matplotlib.pyplot.close()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m)\n\u001b[0;32m-> 1042\u001b[0m manager \u001b[38;5;241m=\u001b[39m \u001b[43mnew_figure_manager\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfigsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframeon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframeon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m    \u001b[49m\u001b[43mFigureClass\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFigureClass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1046\u001b[0m fig \u001b[38;5;241m=\u001b[39m manager\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mfigure\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fig_label:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/matplotlib/pyplot.py:551\u001b[0m, in \u001b[0;36mnew_figure_manager\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnew_figure_manager\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    550\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a new figure manager instance.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 551\u001b[0m     \u001b[43m_warn_if_gui_out_of_main_thread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _get_backend_mod()\u001b[38;5;241m.\u001b[39mnew_figure_manager(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/matplotlib/pyplot.py:528\u001b[0m, in \u001b[0;36m_warn_if_gui_out_of_main_thread\u001b[0;34m()\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_warn_if_gui_out_of_main_thread\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    527\u001b[0m     warn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 528\u001b[0m     canvas_class \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mtype\u001b[39m[FigureCanvasBase], \u001b[43m_get_backend_mod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mFigureCanvas)\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m canvas_class\u001b[38;5;241m.\u001b[39mrequired_interactive_framework:\n\u001b[1;32m    530\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(threading, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_native_id\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    531\u001b[0m             \u001b[38;5;66;03m# This compares native thread ids because even if Python-level\u001b[39;00m\n\u001b[1;32m    532\u001b[0m             \u001b[38;5;66;03m# Thread objects match, the underlying OS thread (which is what\u001b[39;00m\n\u001b[1;32m    533\u001b[0m             \u001b[38;5;66;03m# really matters) may be different on Python implementations with\u001b[39;00m\n\u001b[1;32m    534\u001b[0m             \u001b[38;5;66;03m# green threads.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/matplotlib/pyplot.py:369\u001b[0m, in \u001b[0;36m_get_backend_mod\u001b[0;34m()\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03mEnsure that a backend is selected and return it.\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03mThis is currently private, but may be made public in the future.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _backend_mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;66;03m# Use rcParams._get(\"backend\") to avoid going through the fallback\u001b[39;00m\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;66;03m# logic (which will (re)import pyplot and then call switch_backend if\u001b[39;00m\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# we need to resolve the auto sentinel)\u001b[39;00m\n\u001b[0;32m--> 369\u001b[0m     \u001b[43mswitch_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrcParams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbackend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(\u001b[38;5;28mtype\u001b[39m[matplotlib\u001b[38;5;241m.\u001b[39mbackend_bases\u001b[38;5;241m.\u001b[39m_Backend], _backend_mod)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/matplotlib/pyplot.py:425\u001b[0m, in \u001b[0;36mswitch_backend\u001b[0;34m(newbackend)\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    423\u001b[0m old_backend \u001b[38;5;241m=\u001b[39m rcParams\u001b[38;5;241m.\u001b[39m_get(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackend\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# get without triggering backend resolution\u001b[39;00m\n\u001b[0;32m--> 425\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mbackend_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_backend_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnewbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m canvas_class \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39mFigureCanvas\n\u001b[1;32m    428\u001b[0m required_framework \u001b[38;5;241m=\u001b[39m canvas_class\u001b[38;5;241m.\u001b[39mrequired_interactive_framework\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/matplotlib/backends/registry.py:317\u001b[0m, in \u001b[0;36mBackendRegistry.load_backend_module\u001b[0;34m(self, backend)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;124;03mLoad and return the module containing the specified backend.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;124;03m    Module containing backend.\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    316\u001b[0m module_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend_module_name(backend)\n\u001b[0;32m--> 317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1126\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/matplotlib_inline/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m backend_inline, config  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m      2\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.1.7\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/matplotlib_inline/backend_inline.py:15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minteractiveshell\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InteractiveShell\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgetipython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_ipython\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpylabtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m select_figure_formats\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InlineBackend\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'IPython.core.pylabtools'"
     ]
    }
   ],
   "source": [
    "blstm = BLSTM(\"graph2vec/features/embledding_cwe_469.csv\")\n",
    "blstm.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights loaded successfully.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.0000e+00 - accuracy: 0.0000e+00 - loss: -12574403.0000\n",
      "Test loss: -12949246.0\n",
      "Test accuracy: 0.0\n",
      "Test AUC: 0.0\n"
     ]
    }
   ],
   "source": [
    "blstm.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
