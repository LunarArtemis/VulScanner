{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import confusion_matrix, f1_score, \\\n",
    "    accuracy_score, precision_score, recall_score\n",
    "from torch_geometric.data import Dataset\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import clang.cindex \n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "from sys import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linux\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Configure libclang path\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    print(\"Linux\")\n",
    "    clang.cindex.Config.set_library_file('/usr/lib/llvm-14/lib/libclang.so')\n",
    "elif platform == \"darwin\":\n",
    "    print(\"OS X\")\n",
    "    clang.cindex.Config.set_library_file('/Library/Developer/CommandLineTools/usr/lib/libclang.dylib')\n",
    "elif platform == \"win32\":\n",
    "    print(\"Windows\")\n",
    "    clang.cindex.Config.set_library_file('D:/Project/LLVM/bin/libclang.dll')\n",
    "\n",
    "# Verify if libclang is loaded\n",
    "print(clang.cindex.Config.loaded)  # Should print `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ast(node):\n",
    "    \"\"\"Store the children of the AST node.\"\"\"\n",
    "    node.children = list(node.get_children())\n",
    "    for child in node.children:\n",
    "        save_ast(child)\n",
    "\n",
    "def number_ast_nodes(node, counter=1):\n",
    "    \"\"\"Assign unique identifiers to each node in the AST.\"\"\"\n",
    "    node.identifier = counter\n",
    "    counter += 1\n",
    "\n",
    "    node.children = list(node.get_children())\n",
    "    for child in node.children:\n",
    "        counter = number_ast_nodes(child, counter)\n",
    "\n",
    "    return counter\n",
    "\n",
    "def generate_edgelist(ast_root):\n",
    "    \"\"\"Generate an edge list from the AST.\"\"\"\n",
    "    edges = [[], []]\n",
    "\n",
    "    def walk_tree_and_add_edges(node):\n",
    "        for child in node.children:\n",
    "            edges[0].append(node.identifier - 1)\n",
    "            edges[1].append(child.identifier - 1)\n",
    "            walk_tree_and_add_edges(child)\n",
    "\n",
    "    walk_tree_and_add_edges(ast_root)\n",
    "    return torch.tensor(edges, dtype=torch.long)\n",
    "\n",
    "def generate_features(ast_root):\n",
    "    \"\"\"Generate node features for the AST.\"\"\"\n",
    "    features = []\n",
    "\n",
    "    def walk_tree_and_set_features(node):\n",
    "        out_degree = len(node.children)\n",
    "        node_id = node.identifier\n",
    "        features.append([node_id, out_degree])\n",
    "\n",
    "        for child in node.children:\n",
    "            walk_tree_and_set_features(child)\n",
    "\n",
    "    walk_tree_and_set_features(ast_root)\n",
    "    return torch.tensor(features, dtype=torch.float)\n",
    "\n",
    "def clang_process(testcase):\n",
    "    \"\"\"Process a test case using Clang to generate AST, edges, and features.\"\"\"\n",
    "    parse_list = [(testcase.filename, testcase.code)]\n",
    "\n",
    "    index = clang.cindex.Index.create()\n",
    "    translation_unit = index.parse(path=testcase.filename, unsaved_files=parse_list)\n",
    "    ast_root = translation_unit.cursor\n",
    "\n",
    "    save_ast(ast_root)\n",
    "    number_ast_nodes(ast_root)\n",
    "\n",
    "    edges_embedding = generate_edgelist(ast_root)\n",
    "    nodes_embedding = generate_features(ast_root)\n",
    "    \n",
    "    # Check if it have a vuln or not\n",
    "    \n",
    "    \n",
    "    if hasattr(testcase, \"vuln\"):\n",
    "        y = torch.tensor([testcase.vuln], dtype=torch.int64)\n",
    "    else:\n",
    "        print(\"Attribute 'vuln' not found in testcase.\")\n",
    "\n",
    "\n",
    "    # Clean up Clang objects\n",
    "    del translation_unit, ast_root, index\n",
    "\n",
    "    return Data(x=nodes_embedding, edge_index=edges_embedding, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenDataset(Dataset):\n",
    "    def __init__(self, root, csv_path, transform=None, pre_transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root (str): Root directory where processed data will be stored.\n",
    "            csv_path (str): Path to the CSV file containing the dataset.\n",
    "            transform: Optional transform to be applied to the data.\n",
    "            pre_transform: Optional pre-transform to be applied to the data.\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        super(GenDataset, self).__init__(root, transform, pre_transform)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []  # No raw files are needed\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        \"\"\"Return a list of processed file names.\"\"\"\n",
    "        if not hasattr(self, 'data'):\n",
    "            self.data = pd.read_csv(self.csv_path)\n",
    "        return [f'data_{i}.pt' for i in range(len(self.data))]\n",
    "\n",
    "    def download(self):\n",
    "        \"\"\"No download needed since we are using a local CSV file.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        \"\"\"Load the CSV file and process each row into a graph.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        for index, vuln in tqdm(self.data.iterrows(), total=len(self.data)):\n",
    "            data = clang_process(vuln)\n",
    "            torch.save(data, os.path.join(self.processed_dir, f'data_{index}.pt'))\n",
    "\n",
    "    def len(self):\n",
    "        \"\"\"Return the number of graphs in the dataset.\"\"\"\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        \"\"\"Load a graph from disk.\"\"\"\n",
    "        return torch.load(os.path.join(self.processed_dir, f'data_{idx}.pt'), weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"Datasets/Normalized_CWE-119.csv.gz\"\n",
    "dataset = GenDataset(root='processed_data', csv_path=csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48314"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of features: {dataset[0].num_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges: 23\n",
      "Number of nodes: 24\n"
     ]
    }
   ],
   "source": [
    "tmpData = dataset[2] # Get the first graph object\n",
    "print(f\"Number of edges: {tmpData.num_edges}\")\n",
    "print(f\"Number of nodes: {tmpData.num_nodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1],\n",
      "        [ 1,  2],\n",
      "        [ 2,  3],\n",
      "        [ 1,  4],\n",
      "        [ 1,  5],\n",
      "        [ 1,  6],\n",
      "        [ 1,  7],\n",
      "        [ 7,  8],\n",
      "        [ 8,  9],\n",
      "        [ 7, 10],\n",
      "        [10, 11],\n",
      "        [ 7, 12],\n",
      "        [12, 13],\n",
      "        [13, 14],\n",
      "        [14, 15],\n",
      "        [13, 16],\n",
      "        [16, 17],\n",
      "        [13, 18],\n",
      "        [18, 19],\n",
      "        [13, 20],\n",
      "        [20, 21],\n",
      "        [13, 22],\n",
      "        [22, 23]])\n"
     ]
    }
   ],
   "source": [
    "print(dataset[2].edge_index.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.],\n",
      "        [ 2.,  5.],\n",
      "        [ 3.,  1.],\n",
      "        [ 4.,  0.],\n",
      "        [ 5.,  0.],\n",
      "        [ 6.,  0.],\n",
      "        [ 7.,  0.],\n",
      "        [ 8.,  3.],\n",
      "        [ 9.,  1.],\n",
      "        [10.,  0.],\n",
      "        [11.,  1.],\n",
      "        [12.,  0.],\n",
      "        [13.,  1.],\n",
      "        [14.,  5.],\n",
      "        [15.,  1.],\n",
      "        [16.,  0.],\n",
      "        [17.,  1.],\n",
      "        [18.,  0.],\n",
      "        [19.,  1.],\n",
      "        [20.,  0.],\n",
      "        [21.,  1.],\n",
      "        [22.,  0.],\n",
      "        [23.,  1.],\n",
      "        [24.,  0.]])\n"
     ]
    }
   ],
   "source": [
    "print(dataset[2].x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "print(dataset[2].y) # 1 means vulnerable, 0 means not vulnerable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset.shuffle()\n",
    "one_tenth_length = int(len(data) * 0.1)\n",
    "train_dataset = data[:one_tenth_length * 8]\n",
    "val_dataset = data[one_tenth_length * 8 : one_tenth_length * 9]\n",
    "test_dataset = data[one_tenth_length * 9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38648, 4831, 4835)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "NUM_OF_GRAPHS_PER_BATCH = 256\n",
    "train_dataset_loader = DataLoader(train_dataset, batch_size=NUM_OF_GRAPHS_PER_BATCH, shuffle=True, drop_last=True)\n",
    "val_dataset_loader = DataLoader(val_dataset, batch_size=NUM_OF_GRAPHS_PER_BATCH, shuffle=True, drop_last=True)\n",
    "test_dataset_loader = DataLoader(test_dataset, batch_size=NUM_OF_GRAPHS_PER_BATCH, shuffle=True, drop_last=True)\n",
    "\n",
    "# NUM_OF_GRAPHS_PER_BATCH = 64  # Reduce batch size for better training updates\n",
    "\n",
    "# train_dataset_loader = DataLoader(train_dataset, batch_size=NUM_OF_GRAPHS_PER_BATCH, shuffle=True, drop_last=True)\n",
    "# val_dataset_loader = DataLoader(val_dataset, batch_size=NUM_OF_GRAPHS_PER_BATCH, shuffle=False, drop_last=False)\n",
    "# test_dataset_loader = DataLoader(test_dataset, batch_size=NUM_OF_GRAPHS_PER_BATCH, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters:  82945\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import Linear, Dropout\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool as gap, global_max_pool as gmp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Hyperparameters\n",
    "embedding_size = 128\n",
    "dropout_rate = 0.3\n",
    "learning_rate = 0.001\n",
    "patience = 5\n",
    "num_epochs = 100\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        # Init parent\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "\n",
    "        # GCN layers\n",
    "        self.initial_conv = GCNConv(dataset.num_features, embedding_size) # to translate our node features into the size of the embedding\n",
    "        self.conv1 = GCNConv(embedding_size, embedding_size)\n",
    "        self.conv2 = GCNConv(embedding_size, embedding_size)\n",
    "        \n",
    "        # pooling layer\n",
    "        #self.pool = TopKPooling(embedding_size, ratio=0.8)\n",
    "        #dropout layer\n",
    "        #self.dropout = Dropout(p=0.2)\n",
    "\n",
    "        # Output layer\n",
    "        self.lin1 = Linear(embedding_size*2, 128) # linear output layer ensures that we get a continuous unbounded output value. It input is the flattened vector (embedding size *2) from the pooling layer (mean and max)\n",
    "        self.lin2 = Linear(128, 128)\n",
    "        self.lin3 = Linear(128, 1)\n",
    "        \n",
    "\n",
    "        self.act1 = torch.nn.ReLU()\n",
    "        self.act2 = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x, edge_index, batch_index):\n",
    "        # First Conv layer\n",
    "        hidden = self.initial_conv(x, edge_index)\n",
    "        hidden = F.relu(hidden)\n",
    "\n",
    "        # Other Conv layers\n",
    "        hidden = self.conv1(hidden, edge_index)\n",
    "        hidden = F.relu(hidden)\n",
    "\n",
    "        hidden = self.conv2(hidden, edge_index)\n",
    "        hidden = F.relu(hidden)\n",
    "        #hidden = self.dropout(hidden)\n",
    "        \n",
    "        # Global Pooling (stack different aggregations)\n",
    "        hidden = torch.cat([gmp(hidden, batch_index), \n",
    "                            gap(hidden, batch_index)], dim=1)\n",
    "        \n",
    "        # Apply a final (linear) classifier.\n",
    "        out = self.lin1(hidden)\n",
    "        out = self.act1(out)\n",
    "        out = self.lin2(out)\n",
    "        out = self.act2(out)\n",
    "        #out = F.dropout(out, p=0.5, training=self.training)\n",
    "        out = self.lin3(out)\n",
    "        out = torch.sigmoid(out)\n",
    "\n",
    "        # return out, hidden\n",
    "        return out\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize model\n",
    "#model = GCN(num_features=dataset.num_features).to(device)\n",
    "model = GCN().to(device)\n",
    "print(\"Number of parameters: \", sum(p.numel() for p in model.parameters()))\n",
    "# Update optimizer with weight decay\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5, verbose=True)\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "# Training function\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for data in train_dataset_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x.float(), data.edge_index, data.batch)\n",
    "        label = data.y.to(device)\n",
    "\n",
    "        loss = loss_fn(output.squeeze(), label.float())\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    return total_loss / len(train_dataset_loader)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "\n",
    "            data = data.to(device)\n",
    "            # pred = model(data.x.float(), data.edge_index, data.batch).detach().cpu().numpy()\n",
    "            pred = model(data.x.float(), data.edge_index, data.batch)\n",
    "            label_true = data.y.to(device)\n",
    "            label = data.y.detach().cpu().numpy()\n",
    "            # predictions.append(pred)\n",
    "            # labels.append(label)\n",
    "            predictions.append(np.rint(pred.cpu().detach().numpy()))\n",
    "            labels.append(label)\n",
    "            loss = loss_fn(pred.squeeze(), label_true.float())\n",
    "    # predictions = np.hstack(predictions)\n",
    "    # labels = np.hstack(labels)\n",
    "    predictions = np.concatenate(predictions).ravel()\n",
    "    labels = np.concatenate(labels).ravel()\n",
    "\n",
    "    # print(predictions)\n",
    "    # print(labels)\n",
    "    return accuracy_score(labels, predictions), loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "# Lists to store metrics for plotting\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "# Training loop with early stopping\n",
    "best_val_loss = float('inf')\n",
    "early_stop_counter = 0\n",
    "\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train()\n",
    "    train_acc, _ = evaluate(train_dataset_loader)\n",
    "    val_acc, val_loss = evaluate(val_dataset_loader)\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Store metrics for plotting\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1:3d} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= patience:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "\n",
    "print(f\"Training finished. Best validation loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model_name = 'gcn_cwe_119_test_lr_0001_p5'\n",
    "torch.save(model.state_dict(), model_name + '.pth')\n",
    "torch.save(model,'full_'+ model_name + '.pth')\n",
    "print(\"Model saved to \", model_name+'.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploting learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure tensors are moved to CPU and converted to NumPy\n",
    "train_losses = [loss.cpu().numpy() if isinstance(loss, torch.Tensor) else loss for loss in train_losses]\n",
    "val_losses = [loss.cpu().numpy() if isinstance(loss, torch.Tensor) else loss for loss in val_losses]\n",
    "train_accuracies = [acc.cpu().numpy() if isinstance(acc, torch.Tensor) else acc for acc in train_accuracies]\n",
    "val_accuracies = [acc.cpu().numpy() if isinstance(acc, torch.Tensor) else acc for acc in val_accuracies]\n",
    "\n",
    "# Plot Loss Curve\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label=\"Train Loss\", marker=\"o\")\n",
    "plt.plot(range(1, len(val_losses) + 1), val_losses, label=\"Validation Loss\", marker=\"o\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Learning Curve: Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Plot Accuracy Curve\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label=\"Train Accuracy\", marker=\"o\")\n",
    "plt.plot(range(1, len(val_accuracies) + 1), val_accuracies, label=\"Validation Accuracy\", marker=\"o\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Learning Curve: Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Show plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# subset_ratios = np.linspace(0.1, 1.0, 10)\n",
    "# train_sizes = []\n",
    "# val_accuracies = []\n",
    "\n",
    "# for ratio in subset_ratios:\n",
    "#     subset_size = int(ratio * len(train_dataset))\n",
    "#     subset_loader = DataLoader(torch.utils.data.Subset(train_dataset, range(subset_size)), batch_size=NUM_OF_GRAPHS_PER_BATCH, shuffle=True)\n",
    "    \n",
    "#     model.train()\n",
    "#     for data in subset_loader:\n",
    "#         data = data.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(data.x.float(), data.edge_index, data.batch)\n",
    "#         loss = loss_fn(output.squeeze(), data.y.float())\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "    \n",
    "#     val_acc, _ = evaluate(val_dataset_loader)\n",
    "#     train_sizes.append(subset_size)\n",
    "#     val_accuracies.append(val_acc)\n",
    "\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.plot(train_sizes, val_accuracies, marker='o', linestyle='-', color='b')\n",
    "# plt.xlabel(\"Number of Training Samples\")\n",
    "# plt.ylabel(\"Validation Accuracy\")\n",
    "# plt.title(\"Learning Curve: Data Size vs Accuracy\")\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "NUM_GRAPHS_PER_BATCH_1 = len(test_dataset)\n",
    "test_loader_all = DataLoader(test_dataset, batch_size=NUM_GRAPHS_PER_BATCH_1, drop_last=False, shuffle=True)\n",
    "\n",
    "# Analyze the results for all graphs\n",
    "test_batch = next(iter(test_loader_all))\n",
    "test_batch = test_batch.to(device)  # Move to device\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Forward pass\n",
    "    pred = model(test_batch.x.float(), test_batch.edge_index, test_batch.batch)\n",
    "\n",
    "    # Convert predictions to binary (0 or 1)\n",
    "    pred_bin = np.rint(pred.cpu().numpy())  # Convert tensor → NumPy → Rounded binary values\n",
    "    # pred_bin = np.rint(pred.detach().cpu().numpy())\n",
    "    y_true = test_batch.y.cpu().numpy()  # Convert tensor → NumPy\n",
    "\n",
    "    # Compute evaluation metrics\n",
    "    accuracy = accuracy_score(y_true, pred_bin)\n",
    "    precision = precision_score(y_true, pred_bin, zero_division=1)\n",
    "    recall = recall_score(y_true, pred_bin, zero_division=1)\n",
    "    f1 = f1_score(y_true, pred_bin)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, pred_bin)\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"\\n Confusion matrix: \\n {cm}\")\n",
    "    print(f\"\\n Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"\\n Precision: {precision:.4f}\")\n",
    "    print(f\"\\n Recall: {recall:.4f}\")\n",
    "    print(f\"\\n F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Save results in a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"y_real\": y_true.tolist(),\n",
    "        \"y_pred_bin\": pred_bin.tolist(),\n",
    "        \"y_pred_float\": pred.tolist()\n",
    "    })\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Non-Vulnerable\", \"Vulnerable\"], yticklabels=[\"Non-Vulnerable\", \"Vulnerable\"])\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "df  # Display DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions with source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Load the model architecture\n",
    "model_pred = GCN().to(device)\n",
    "\n",
    "# Load the trained weights\n",
    "# model.load_state_dict(torch.load('gcn_cwe_119.pth'))\n",
    "#model_pred.load_state_dict(torch.load('gcn_cwe_119_test_lr_0005.pth'))\n",
    "model_pred = torch.load(\"full_gcn_cwe_119_test_lr_0005.pth\")\n",
    "model_pred.eval()  # Set the model to evaluation mode\n",
    "\n",
    "class TestCase:\n",
    "    def __init__(self, filename, code, vuln=None):\n",
    "        self.filename = filename\n",
    "        self.code = code\n",
    "        self.vuln = vuln\n",
    "\n",
    "# Load the source code files\n",
    "with open('Sourcecode/no_vuln.c', 'r') as f:\n",
    "    clear_area_code = f.read()\n",
    "\n",
    "with open('Sourcecode/cwe_119_1.c', 'r') as f:\n",
    "    hello_world_code = f.read()\n",
    "\n",
    "# Create test case objects with vuln set to False\n",
    "clear_area_testcase = TestCase(filename='clear_area.c', code=clear_area_code, vuln=False)\n",
    "vuln_testcase = TestCase(filename='cwe_119_1.c', code=hello_world_code, vuln=True)\n",
    "\n",
    "# Preprocess the source code files\n",
    "clear_area_data = clang_process(clear_area_testcase)\n",
    "vuln_data = clang_process(vuln_testcase)\n",
    "\n",
    "print(\"clear_area.c features:\", clear_area_data.x)\n",
    "print(\"cwe_119_1.c features:\", vuln_data.x)\n",
    "\n",
    "def predict_vulnerability(data):\n",
    "    data = data.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(data.x.float(), data.edge_index, data.batch) # Trained model\n",
    "        # output = model_pred(data.x.float(), data.edge_index, data.batch) # Saved model\n",
    "        probability = output.item()  # Get the raw probability\n",
    "        prediction = torch.round(output).item()  # Round to 0 or 1\n",
    "    return probability, prediction\n",
    "    \n",
    "\n",
    "# Predict for clear_area.c\n",
    "clear_area_prob, clear_area_pred = predict_vulnerability(clear_area_data)\n",
    "print(f\"Probability for clear_area.c: {clear_area_prob:.4f}, Prediction: {'Vulnerable' if clear_area_pred == 1 else 'Safe'}\")\n",
    "\n",
    "# Predict for hello_world.c\n",
    "vuln_prob, vuln_pred = predict_vulnerability(vuln_data)\n",
    "print(f\"Probability for cwe_119_1.c: {vuln_prob:.4f}, Prediction: {'Vulnerable' if vuln_pred == 1 else 'Safe'}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
