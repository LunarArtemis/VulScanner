{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows the steps related to extraxing ASTs from source code using Clang. It prepares the graph representation for the first approach, which is based on graph2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook some functions are written with some help from the following documentations as well as tutorials: \n",
    "\n",
    "Clang documentation:\n",
    "\n",
    "https://libclang.readthedocs.io/en/latest/index.html\n",
    "\n",
    "An example of parsing C ++ code using libclang in Python:\n",
    "\n",
    "https://sudonull.com/post/907-An-example-of-parsing-C-code-using-libclang-in-Python\n",
    "\n",
    "Clang tutorial:\n",
    "\n",
    "https://jonasdevlieghere.com/understanding-the-clang-ast/#cursors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clang.cindex\n",
    "import json\n",
    "import os\n",
    "import dask.dataframe as dd # for parallel computing \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ctypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uploading a processed CWE type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clang.cindex.Config.set_library_file('D:/Project/LLVM/bin/libclang.dll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdisc = pd.read_csv(\"Datasets/Normalized_CWE-469.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ast(node):\n",
    "   \n",
    "    node.children = list(node.get_children())\n",
    "\n",
    "    for child in node.children:\n",
    "        counter = save_ast(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numbering_ast_nodes(node, counter=1):\n",
    "  \n",
    "    node.identifier = counter\n",
    "    counter += 1\n",
    "\n",
    "    node.children = list(node.get_children())\n",
    "    for child in node.children:\n",
    "        counter = numbering_ast_nodes(child, counter)\n",
    "\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_edgelist(ast_root):\n",
    "  \n",
    "    edges = []\n",
    "\n",
    "    def walk_tree_and_add_edges(node):\n",
    "        for child in node.children:\n",
    "            edges.append([node.identifier, child.identifier])\n",
    "            walk_tree_and_add_edges(child)\n",
    "\n",
    "    walk_tree_and_add_edges(ast_root)\n",
    "\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build features that include node index and degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(ast_root):\n",
    "    \n",
    "    features = {}\n",
    "\n",
    "    def walk_tree_and_set_features(node):\n",
    "        out_degree = len(node.children)\n",
    "        #in_degree = 1\n",
    "        #degree = out_degree + in_degree\n",
    "        degree = out_degree\n",
    "\n",
    "        features[node.identifier] = degree\n",
    "\n",
    "        for child in node.children:\n",
    "            walk_tree_and_set_features(child)\n",
    "\n",
    "    walk_tree_and_set_features(ast_root)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source_file(datapoints):\n",
    "    if len(datapoints) == 1:\n",
    "        return datapoints.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clang_process(testcase, **kwargs):\n",
    "    \n",
    "    parse_list = [\n",
    "        (datapoint.filename, datapoint.code)\n",
    "        for datapoint in testcase.itertuples()\n",
    "    ]\n",
    "\n",
    "    source_file= get_source_file(testcase)\n",
    "\n",
    "    # Parsing the source code and extracting AST using clang\n",
    "    index = clang.cindex.Index.create()\n",
    "    translation_unit = index.parse(\n",
    "        path=source_file.filename,\n",
    "        unsaved_files=parse_list,\n",
    "    )\n",
    "    ast_root = translation_unit.cursor\n",
    "\n",
    "    save_ast(ast_root)\n",
    "    numbering_ast_nodes(ast_root)\n",
    "\n",
    "    edgelist = generate_edgelist(ast_root)\n",
    "\n",
    "    features = generate_features(ast_root)\n",
    "\n",
    "    graph_representation = {\n",
    "        \"edges\": edgelist,\n",
    "        \"features\": features,\n",
    "    }\n",
    "\n",
    "    # delete clang objects\n",
    "    del translation_unit\n",
    "    del ast_root\n",
    "    del index\n",
    "\n",
    "    # Writing to sample.json\n",
    "    # with open(\"sample.json\", \"w\") as outfile:\n",
    "    #     json.dump(graph2vec_representation,outfile)\n",
    "    return json.dumps(graph_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_Representation_process(csv_location, output_location, num_partitions=20):\n",
    "    print(\"Preprocess source code files and extracting AST's\")\n",
    "\n",
    "    data = pd.read_csv(csv_location)\n",
    "    data = dd.from_pandas(data, npartitions=num_partitions)\n",
    "\n",
    "    graphs = data.groupby(['testID']).apply(\n",
    "        clang_process,\n",
    "        axis='columns',\n",
    "        meta=('processed_for_graph2vec', 'unicode'),\n",
    "    )\n",
    "\n",
    "    graph2vec_input_dir = output_location + \"/graph2vec_input/\"\n",
    "    os.makedirs(graph2vec_input_dir, exist_ok=True)\n",
    "\n",
    "    for index, row in graphs.iteritems():\n",
    "        print(\"Current Iteration: \"+str(index))\n",
    "        with open(graph2vec_input_dir + str(index) + \".json\", 'w') as f:\n",
    "            f.write(row)\n",
    "\n",
    "    print(\"`-> Done.\")\n",
    "\n",
    "    return graph2vec_input_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process all source code using dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess source code files and extracting AST's\n"
     ]
    },
    {
     "ename": "TranslationUnitLoadError",
     "evalue": "Error parsing translation unit.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTranslationUnitLoadError\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m csvLocation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasets/Normalized_CWE-469.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m outputLocation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgraph2vec/dataset/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mgraph_Representation_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsvLocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputLocation\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 11\u001b[0m, in \u001b[0;36mgraph_Representation_process\u001b[1;34m(csv_location, output_location, num_partitions)\u001b[0m\n\u001b[0;32m      4\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(csv_location)\n\u001b[0;32m      5\u001b[0m data \u001b[38;5;241m=\u001b[39m dd\u001b[38;5;241m.\u001b[39mfrom_pandas(data, npartitions\u001b[38;5;241m=\u001b[39mnum_partitions)\n\u001b[0;32m      7\u001b[0m graphs \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtestID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclang_process\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprocessed_for_graph2vec\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43municode\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m---> 11\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Convert to Pandas DataFrame\u001b[39;00m\n\u001b[0;32m     13\u001b[0m graph2vec_input_dir \u001b[38;5;241m=\u001b[39m output_location \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/graph2vec_input/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     14\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(graph2vec_input_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\ireen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\dataframe\\dask_expr\\_collection.py:489\u001b[0m, in \u001b[0;36mFrameBase.compute\u001b[1;34m(self, fuse, concatenate, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mrepartition(npartitions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    488\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39moptimize(fuse\u001b[38;5;241m=\u001b[39mfuse)\n\u001b[1;32m--> 489\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDaskMethodsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ireen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\base.py:374\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    351\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \n\u001b[0;32m    353\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 374\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\ireen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\base.py:662\u001b[0m, in \u001b[0;36mcompute\u001b[1;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[0;32m    659\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m    661\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[1;32m--> 662\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[1;32mc:\\Users\\ireen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\dataframe\\dask_expr\\_groupby.py:1200\u001b[0m, in \u001b[0;36mGroupByUDFBlockwise.operation\u001b[1;34m(frame, _slice, group_keys, observed, dropna, args, kwargs, dask_func, *by)\u001b[0m\n\u001b[0;32m   1198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1199\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m-> 1200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdask_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mby\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_slice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_as_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mobserved\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1207\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_as_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdropna\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1208\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1209\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ireen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\dataframe\\dask_expr\\_groupby.py:1236\u001b[0m, in \u001b[0;36mgroupby_slice_apply\u001b[1;34m(df, grouper, key, func, args, group_keys, dropna, observed, **kwargs)\u001b[0m\n\u001b[0;32m   1225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgroupby_slice_apply\u001b[39m(\n\u001b[0;32m   1226\u001b[0m     df,\n\u001b[0;32m   1227\u001b[0m     grouper,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1235\u001b[0m ):\n\u001b[1;32m-> 1236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_groupby_slice_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrouper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ireen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\dataframe\\groupby.py:116\u001b[0m, in \u001b[0;36m_groupby_slice_apply\u001b[1;34m(df, grouper, key, func, group_keys, dropna, observed, *args, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key:\n\u001b[0;32m    115\u001b[0m     g \u001b[38;5;241m=\u001b[39m g[key]\n\u001b[1;32m--> 116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 12\u001b[0m, in \u001b[0;36mclang_process\u001b[1;34m(testcase, **kwargs)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Parsing the source code and extracting AST using clang\u001b[39;00m\n\u001b[0;32m     11\u001b[0m index \u001b[38;5;241m=\u001b[39m clang\u001b[38;5;241m.\u001b[39mcindex\u001b[38;5;241m.\u001b[39mIndex\u001b[38;5;241m.\u001b[39mcreate()\n\u001b[1;32m---> 12\u001b[0m translation_unit \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43munsaved_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m ast_root \u001b[38;5;241m=\u001b[39m translation_unit\u001b[38;5;241m.\u001b[39mcursor\n\u001b[0;32m     18\u001b[0m save_ast(ast_root)\n",
      "File \u001b[1;32mc:\\Users\\ireen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\clang\\cindex.py:2989\u001b[0m, in \u001b[0;36mIndex.parse\u001b[1;34m(self, path, args, unsaved_files, options)\u001b[0m\n\u001b[0;32m   2976\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, path, args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, unsaved_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m   2977\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load the translation unit from the given source code file by running\u001b[39;00m\n\u001b[0;32m   2978\u001b[0m \u001b[38;5;124;03m    clang and generating the AST before loading. Additional command line\u001b[39;00m\n\u001b[0;32m   2979\u001b[0m \u001b[38;5;124;03m    parameters can be passed to clang via the args parameter.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2987\u001b[0m \u001b[38;5;124;03m    will be raised.\u001b[39;00m\n\u001b[0;32m   2988\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2989\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTranslationUnit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_source\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munsaved_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ireen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\clang\\cindex.py:3109\u001b[0m, in \u001b[0;36mTranslationUnit.from_source\u001b[1;34m(cls, filename, args, unsaved_files, options, index)\u001b[0m\n\u001b[0;32m   3098\u001b[0m ptr \u001b[38;5;241m=\u001b[39m conf\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39mclang_parseTranslationUnit(\n\u001b[0;32m   3099\u001b[0m     index,\n\u001b[0;32m   3100\u001b[0m     os\u001b[38;5;241m.\u001b[39mfspath(filename) \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3105\u001b[0m     options,\n\u001b[0;32m   3106\u001b[0m )\n\u001b[0;32m   3108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ptr:\n\u001b[1;32m-> 3109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TranslationUnitLoadError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError parsing translation unit.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(ptr, index\u001b[38;5;241m=\u001b[39mindex)\n",
      "\u001b[1;31mTranslationUnitLoadError\u001b[0m: Error parsing translation unit."
     ]
    }
   ],
   "source": [
    "csvLocation = \"Datasets/Normalized_CWE-469.csv\"\n",
    "outputLocation = \"graph2vec/dataset/\"\n",
    "\n",
    "graph_Representation_process(csvLocation, outputLocation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
