{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InMemoryDataset\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "File \u001b[1;32mc:\\Users\\ireen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\__init__.py:2486\u001b[0m\n\u001b[0;32m   2482\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m vmap \u001b[38;5;28;01mas\u001b[39;00m vmap\n\u001b[0;32m   2485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m-> 2486\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations\n\u001b[0;32m   2488\u001b[0m \u001b[38;5;66;03m# Enable CUDA Sanitizer\u001b[39;00m\n\u001b[0;32m   2489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTORCH_CUDA_SANITIZER\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n",
      "File \u001b[1;32mc:\\Users\\ireen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_meta_registrations.py:6636\u001b[0m\n\u001b[0;32m   6632\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6633\u001b[0m                 _meta_lib_dont_use_me_use_register_meta\u001b[38;5;241m.\u001b[39mimpl(op_overload, fn)\n\u001b[1;32m-> 6636\u001b[0m \u001b[43mactivate_meta\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ireen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_meta_registrations.py:6633\u001b[0m, in \u001b[0;36mactivate_meta\u001b[1;34m()\u001b[0m\n\u001b[0;32m   6629\u001b[0m     _meta_lib_dont_use_me_use_register_meta_for_quantized\u001b[38;5;241m.\u001b[39mimpl(\n\u001b[0;32m   6630\u001b[0m         op_overload, fn\n\u001b[0;32m   6631\u001b[0m     )\n\u001b[0;32m   6632\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 6633\u001b[0m     \u001b[43m_meta_lib_dont_use_me_use_register_meta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_overload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ireen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\library.py:323\u001b[0m, in \u001b[0;36mLibrary.impl\u001b[1;34m(self, op_name, fn, dispatch_key, with_keyset)\u001b[0m\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    316\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe should not register a meta kernel directly to the operator \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    317\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m because it has a CompositeImplicitAutograd kernel in core.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    318\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Instead we should let the operator decompose, and ensure that we have meta kernels\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    319\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for the base ops that it decomposes into.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         )\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 323\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdispatch_key\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdispatch_key\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCompositeImplicitAutograd\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_keyset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    330\u001b[0m _impls\u001b[38;5;241m.\u001b[39madd(key)\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op_impls\u001b[38;5;241m.\u001b[39madd(key)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:230\u001b[0m, in \u001b[0;36m_lock_unlock_module\u001b[1;34m(name)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:125\u001b[0m, in \u001b[0;36mrelease\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import confusion_matrix, f1_score, \\\n",
    "    accuracy_score, precision_score, recall_score\n",
    "from torch_geometric.data import Dataset\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import clang.cindex \n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "from sys import platform\n",
    "\n",
    "import torch\n",
    "from torch.nn import Linear, Dropout\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool as gap, global_max_pool as gmp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linux\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Configure libclang path\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    print(\"Linux\")\n",
    "    clang.cindex.Config.set_library_file('/usr/lib/llvm-14/lib/libclang.so')\n",
    "elif platform == \"darwin\":\n",
    "    print(\"OS X\")\n",
    "    clang.cindex.Config.set_library_file('/Library/Developer/CommandLineTools/usr/lib/libclang.dylib')\n",
    "elif platform == \"win32\":\n",
    "    print(\"Windows\")\n",
    "    clang.cindex.Config.set_library_file('D:/Project/LLVM/bin/libclang.dll')\n",
    "\n",
    "# Verify if libclang is loaded\n",
    "print(clang.cindex.Config.loaded)  # Should print `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ast(node):\n",
    "    \"\"\"Store the children of the AST node.\"\"\"\n",
    "    node.children = list(node.get_children())\n",
    "    for child in node.children:\n",
    "        save_ast(child)\n",
    "\n",
    "def number_ast_nodes(node, counter=1):\n",
    "    \"\"\"Assign unique identifiers to each node in the AST.\"\"\"\n",
    "    node.identifier = counter\n",
    "    counter += 1\n",
    "\n",
    "    node.children = list(node.get_children())\n",
    "    for child in node.children:\n",
    "        counter = number_ast_nodes(child, counter)\n",
    "\n",
    "    return counter\n",
    "\n",
    "def generate_edgelist(ast_root):\n",
    "    \"\"\"Generate an edge list from the AST.\"\"\"\n",
    "    edges = [[], []]\n",
    "\n",
    "    def walk_tree_and_add_edges(node):\n",
    "        for child in node.children:\n",
    "            edges[0].append(node.identifier - 1)\n",
    "            edges[1].append(child.identifier - 1)\n",
    "            walk_tree_and_add_edges(child)\n",
    "\n",
    "    walk_tree_and_add_edges(ast_root)\n",
    "    return torch.tensor(edges, dtype=torch.long)\n",
    "\n",
    "def generate_features(ast_root):\n",
    "    \"\"\"Generate node features for the AST.\"\"\"\n",
    "    features = []\n",
    "\n",
    "    def walk_tree_and_set_features(node):\n",
    "        out_degree = len(node.children)\n",
    "        node_id = node.identifier\n",
    "        features.append([node_id, out_degree])\n",
    "\n",
    "        for child in node.children:\n",
    "            walk_tree_and_set_features(child)\n",
    "\n",
    "    walk_tree_and_set_features(ast_root)\n",
    "    return torch.tensor(features, dtype=torch.float)\n",
    "\n",
    "def clang_process(testcase):\n",
    "    \"\"\"Process a test case using Clang to generate AST, edges, and features.\"\"\"\n",
    "    parse_list = [(testcase.filename, testcase.code)]\n",
    "\n",
    "    index = clang.cindex.Index.create()\n",
    "    translation_unit = index.parse(path=testcase.filename, unsaved_files=parse_list)\n",
    "    ast_root = translation_unit.cursor\n",
    "\n",
    "    save_ast(ast_root)\n",
    "    number_ast_nodes(ast_root)\n",
    "\n",
    "    edges_embedding = generate_edgelist(ast_root)\n",
    "    nodes_embedding = generate_features(ast_root)\n",
    "    \n",
    "    # Check if it have a vuln or not\n",
    "    \n",
    "    \n",
    "    if hasattr(testcase, \"vuln\"):\n",
    "        y = torch.tensor([testcase.vuln], dtype=torch.int64)\n",
    "    else:\n",
    "        print(\"Attribute 'vuln' not found in testcase.\")\n",
    "\n",
    "\n",
    "    # Clean up Clang objects\n",
    "    del translation_unit, ast_root, index\n",
    "\n",
    "    return Data(x=nodes_embedding, edge_index=edges_embedding, y=y)\n",
    "\n",
    "class GenDataset(Dataset):\n",
    "    def __init__(self, root, csv_path, transform=None, pre_transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root (str): Root directory where processed data will be stored.\n",
    "            csv_path (str): Path to the CSV file containing the dataset.\n",
    "            transform: Optional transform to be applied to the data.\n",
    "            pre_transform: Optional pre-transform to be applied to the data.\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        super(GenDataset, self).__init__(root, transform, pre_transform)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []  # No raw files are needed\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        \"\"\"Return a list of processed file names.\"\"\"\n",
    "        if not hasattr(self, 'data'):\n",
    "            self.data = pd.read_csv(self.csv_path)\n",
    "        return [f'data_{i}.pt' for i in range(len(self.data))]\n",
    "\n",
    "    def download(self):\n",
    "        \"\"\"No download needed since we are using a local CSV file.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        \"\"\"Load the CSV file and process each row into a graph.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        for index, vuln in tqdm(self.data.iterrows(), total=len(self.data)):\n",
    "            data = clang_process(vuln)\n",
    "            torch.save(data, os.path.join(self.processed_dir, f'data_{index}.pt'))\n",
    "\n",
    "    def len(self):\n",
    "        \"\"\"Return the number of graphs in the dataset.\"\"\"\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        \"\"\"Load a graph from disk.\"\"\"\n",
    "        return torch.load(os.path.join(self.processed_dir, f'data_{idx}.pt'), weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear, Dropout\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool as gap, global_max_pool as gmp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Hyperparameters\n",
    "embedding_size = 128\n",
    "dropout_rate = 0.3\n",
    "learning_rate = 0.001\n",
    "patience = 5\n",
    "num_epochs = 100\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self,num_features):\n",
    "        # Init parent\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "\n",
    "        # GCN layers\n",
    "        # self.initial_conv = GCNConv(dataset.num_features, embedding_size) # to translate our node features into the size of the embedding\n",
    "        self.initial_conv = GCNConv(num_features, embedding_size) \n",
    "        self.conv1 = GCNConv(embedding_size, embedding_size)\n",
    "        self.conv2 = GCNConv(embedding_size, embedding_size)\n",
    "        \n",
    "        # pooling layer\n",
    "        #self.pool = TopKPooling(embedding_size, ratio=0.8)\n",
    "        #dropout layer\n",
    "        #self.dropout = Dropout(p=0.2)\n",
    "\n",
    "        # Output layer\n",
    "        self.lin1 = Linear(embedding_size*2, 128) # linear output layer ensures that we get a continuous unbounded output value. It input is the flattened vector (embedding size *2) from the pooling layer (mean and max)\n",
    "        self.lin2 = Linear(128, 128)\n",
    "        self.lin3 = Linear(128, 1)\n",
    "        \n",
    "\n",
    "        self.act1 = torch.nn.ReLU()\n",
    "        self.act2 = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x, edge_index, batch_index):\n",
    "        # First Conv layer\n",
    "        hidden = self.initial_conv(x, edge_index)\n",
    "        hidden = F.relu(hidden)\n",
    "\n",
    "        # Other Conv layers\n",
    "        hidden = self.conv1(hidden, edge_index)\n",
    "        hidden = F.relu(hidden)\n",
    "\n",
    "        hidden = self.conv2(hidden, edge_index)\n",
    "        hidden = F.relu(hidden)\n",
    "        #hidden = self.dropout(hidden)\n",
    "        \n",
    "        # Global Pooling (stack different aggregations)\n",
    "        hidden = torch.cat([gmp(hidden, batch_index), \n",
    "                            gap(hidden, batch_index)], dim=1)\n",
    "        \n",
    "        # Apply a final (linear) classifier.\n",
    "        out = self.lin1(hidden)\n",
    "        out = self.act1(out)\n",
    "        out = self.lin2(out)\n",
    "        out = self.act2(out)\n",
    "        #out = F.dropout(out, p=0.5, training=self.training)\n",
    "        out = self.lin3(out)\n",
    "        out = torch.sigmoid(out)\n",
    "\n",
    "        # return out, hidden\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear_area.c features: tensor([[1.0000e+00, 6.8800e+02],\n",
      "        [2.0000e+00, 0.0000e+00],\n",
      "        [3.0000e+00, 1.0000e+00],\n",
      "        ...,\n",
      "        [2.5800e+03, 0.0000e+00],\n",
      "        [2.5810e+03, 1.0000e+00],\n",
      "        [2.5820e+03, 0.0000e+00]])\n",
      "cwe_119_1.c features: tensor([[ 1.,  1.],\n",
      "        [ 2.,  2.],\n",
      "        [ 3.,  0.],\n",
      "        [ 4.,  4.],\n",
      "        [ 5.,  2.],\n",
      "        [ 6.,  0.],\n",
      "        [ 7.,  1.],\n",
      "        [ 8.,  0.],\n",
      "        [ 9.,  1.],\n",
      "        [10.,  1.],\n",
      "        [11.,  0.],\n",
      "        [12.,  2.],\n",
      "        [13.,  1.],\n",
      "        [14.,  0.],\n",
      "        [15.,  1.],\n",
      "        [16.,  0.],\n",
      "        [17.,  3.],\n",
      "        [18.,  0.],\n",
      "        [19.,  0.],\n",
      "        [20.,  1.],\n",
      "        [21.,  0.]])\n",
      "clear_area.c - Probability: 0.0000, Prediction: Safe, Avg Inference Time: 3.113 ms\n",
      "cwe_119_1.c - Probability: 0.6831, Prediction: Vulnerable, Avg Inference Time: 2.523 ms\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the model\n",
    "model_pred = torch.load(\"full_gcn_cwe_119_test_lr_0005.pth\")\n",
    "model_pred.to(device)\n",
    "model_pred.eval()  # Set the model to evaluation mode\n",
    "\n",
    "class TestCase:\n",
    "    def __init__(self, filename, code, vuln=None):\n",
    "        self.filename = filename\n",
    "        self.code = code\n",
    "        self.vuln = vuln\n",
    "\n",
    "# Load the source code files\n",
    "with open('Sourcecode/no_vuln.c', 'r') as f:\n",
    "    clear_area_code = f.read()\n",
    "\n",
    "with open('Sourcecode/cwe_119_1.c', 'r') as f:\n",
    "    hello_world_code = f.read()\n",
    "\n",
    "# Create test case objects\n",
    "clear_area_testcase = TestCase(filename='clear_area.c', code=clear_area_code, vuln=False)\n",
    "vuln_testcase = TestCase(filename='cwe_119_1.c', code=hello_world_code, vuln=True)\n",
    "\n",
    "# Preprocess the source code files\n",
    "clear_area_data = clang_process(clear_area_testcase)\n",
    "vuln_data = clang_process(vuln_testcase)\n",
    "\n",
    "print(\"clear_area.c features:\", clear_area_data.x)\n",
    "print(\"cwe_119_1.c features:\", vuln_data.x)\n",
    "\n",
    "def predict_vulnerability(data, num_runs=5):\n",
    "    \"\"\"\n",
    "    Perform multiple inference runs and measure execution time in milliseconds.\n",
    "    \"\"\"\n",
    "    data = data.to(device)\n",
    "    \n",
    "    times = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_runs):\n",
    "            start_time = time.time()  # Start time\n",
    "\n",
    "            output = model(data.x.float(), data.edge_index, data.batch) # Train model\n",
    "            # output = model_pred(data.x.float(), data.edge_index, data.batch) # Saved train model\n",
    "            end_time = time.time()  # End time\n",
    "            \n",
    "            elapsed_time_ms = (end_time - start_time) * 1000  # Convert to milliseconds\n",
    "            times.append(elapsed_time_ms)\n",
    "        \n",
    "        probability = output.item()  # Get probability\n",
    "        prediction = torch.round(output).item()  # Round to 0 or 1\n",
    "    \n",
    "    avg_time_ms = sum(times) / num_runs  # Compute average inference time in ms\n",
    "    return probability, prediction, avg_time_ms\n",
    "\n",
    "# Perform inference with time measurement in milliseconds\n",
    "clear_area_prob, clear_area_pred, clear_area_time_ms = predict_vulnerability(clear_area_data)\n",
    "print(f\"clear_area.c - Probability: {clear_area_prob:.4f}, Prediction: {'Vulnerable' if clear_area_pred == 1 else 'Safe'}, Avg Inference Time: {clear_area_time_ms:.3f} ms\")\n",
    "\n",
    "vuln_prob, vuln_pred, vuln_time_ms = predict_vulnerability(vuln_data)\n",
    "print(f\"cwe_119_1.c - Probability: {vuln_prob:.4f}, Prediction: {'Vulnerable' if vuln_pred == 1 else 'Safe'}, Avg Inference Time: {vuln_time_ms:.3f} ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear_area.c - Avg Time: 16.274 ms (10 runs)\n",
      "cwe_119_1.c - Avg Time: 13.037 ms (10 runs)\n",
      "\n",
      "Overall Average Inference Time: 14.656 ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def measure_avg_time(data_samples, num_runs=10):\n",
    "    \"\"\"Measures average inference time over multiple runs.\"\"\"\n",
    "    total_time = 0.0\n",
    "    for _ in range(num_runs):\n",
    "        start = time.perf_counter()\n",
    "        predict_vulnerability(data_samples)  # We ignore output for timing\n",
    "        end = time.perf_counter()\n",
    "        total_time += (end - start) * 1000  # Convert to milliseconds\n",
    "    return total_time / num_runs\n",
    "\n",
    "# Measure average time for each\n",
    "avg_time_clear = measure_avg_time(clear_area_data)\n",
    "avg_time_vuln = measure_avg_time(vuln_data)\n",
    "\n",
    "# Combined average\n",
    "overall_avg_time = (avg_time_clear + avg_time_vuln) / 2\n",
    "\n",
    "print(f\"clear_area.c - Avg Time: {avg_time_clear:.3f} ms (10 runs)\")\n",
    "print(f\"cwe_119_1.c - Avg Time: {avg_time_vuln:.3f} ms (10 runs)\")\n",
    "print(f\"\\nOverall Average Inference Time: {overall_avg_time:.3f} ms\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
