{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import confusion_matrix, f1_score, \\\n",
    "    accuracy_score, precision_score, recall_score\n",
    "from torch_geometric.data import Dataset\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import clang.cindex \n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "from sys import platform\n",
    "\n",
    "import torch\n",
    "from torch.nn import Linear, Dropout\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool as gap, global_max_pool as gmp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Configure libclang path\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    print(\"Linux\")\n",
    "    clang.cindex.Config.set_library_file('/usr/lib/llvm-14/lib/libclang.so')\n",
    "elif platform == \"darwin\":\n",
    "    print(\"OS X\")\n",
    "    clang.cindex.Config.set_library_file('/Library/Developer/CommandLineTools/usr/lib/libclang.dylib')\n",
    "elif platform == \"win32\":\n",
    "    print(\"Windows\")\n",
    "    clang.cindex.Config.set_library_file('D:/Project/LLVM/bin/libclang.dll')\n",
    "\n",
    "# Verify if libclang is loaded\n",
    "print(clang.cindex.Config.loaded)  # Should print `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ast(node):\n",
    "    \"\"\"Store the children of the AST node.\"\"\"\n",
    "    node.children = list(node.get_children())\n",
    "    for child in node.children:\n",
    "        save_ast(child)\n",
    "\n",
    "def number_ast_nodes(node, counter=1):\n",
    "    \"\"\"Assign unique identifiers to each node in the AST.\"\"\"\n",
    "    node.identifier = counter\n",
    "    counter += 1\n",
    "\n",
    "    node.children = list(node.get_children())\n",
    "    for child in node.children:\n",
    "        counter = number_ast_nodes(child, counter)\n",
    "\n",
    "    return counter\n",
    "\n",
    "def generate_edgelist(ast_root):\n",
    "    \"\"\"Generate an edge list from the AST.\"\"\"\n",
    "    edges = [[], []]\n",
    "\n",
    "    def walk_tree_and_add_edges(node):\n",
    "        for child in node.children:\n",
    "            edges[0].append(node.identifier - 1)\n",
    "            edges[1].append(child.identifier - 1)\n",
    "            walk_tree_and_add_edges(child)\n",
    "\n",
    "    walk_tree_and_add_edges(ast_root)\n",
    "    return torch.tensor(edges, dtype=torch.long)\n",
    "\n",
    "def generate_features(ast_root):\n",
    "    \"\"\"Generate node features for the AST.\"\"\"\n",
    "    features = []\n",
    "\n",
    "    def walk_tree_and_set_features(node):\n",
    "        out_degree = len(node.children)\n",
    "        node_id = node.identifier\n",
    "        features.append([node_id, out_degree])\n",
    "\n",
    "        for child in node.children:\n",
    "            walk_tree_and_set_features(child)\n",
    "\n",
    "    walk_tree_and_set_features(ast_root)\n",
    "    return torch.tensor(features, dtype=torch.float)\n",
    "\n",
    "def clang_process(testcase):\n",
    "    \"\"\"Process a test case using Clang to generate AST, edges, and features.\"\"\"\n",
    "    parse_list = [(testcase.filename, testcase.code)]\n",
    "\n",
    "    index = clang.cindex.Index.create()\n",
    "    translation_unit = index.parse(path=testcase.filename, unsaved_files=parse_list)\n",
    "    ast_root = translation_unit.cursor\n",
    "\n",
    "    save_ast(ast_root)\n",
    "    number_ast_nodes(ast_root)\n",
    "\n",
    "    edges_embedding = generate_edgelist(ast_root)\n",
    "    nodes_embedding = generate_features(ast_root)\n",
    "    \n",
    "    # Check if it have a vuln or not\n",
    "    \n",
    "    \n",
    "    if hasattr(testcase, \"vuln\"):\n",
    "        y = torch.tensor([testcase.vuln], dtype=torch.int64)\n",
    "    else:\n",
    "        print(\"Attribute 'vuln' not found in testcase.\")\n",
    "\n",
    "\n",
    "    # Clean up Clang objects\n",
    "    del translation_unit, ast_root, index\n",
    "\n",
    "    return Data(x=nodes_embedding, edge_index=edges_embedding, y=y)\n",
    "\n",
    "class GenDataset(Dataset):\n",
    "    def __init__(self, root, csv_path, transform=None, pre_transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root (str): Root directory where processed data will be stored.\n",
    "            csv_path (str): Path to the CSV file containing the dataset.\n",
    "            transform: Optional transform to be applied to the data.\n",
    "            pre_transform: Optional pre-transform to be applied to the data.\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        super(GenDataset, self).__init__(root, transform, pre_transform)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []  # No raw files are needed\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        \"\"\"Return a list of processed file names.\"\"\"\n",
    "        if not hasattr(self, 'data'):\n",
    "            self.data = pd.read_csv(self.csv_path)\n",
    "        return [f'data_{i}.pt' for i in range(len(self.data))]\n",
    "\n",
    "    def download(self):\n",
    "        \"\"\"No download needed since we are using a local CSV file.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        \"\"\"Load the CSV file and process each row into a graph.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        for index, vuln in tqdm(self.data.iterrows(), total=len(self.data)):\n",
    "            data = clang_process(vuln)\n",
    "            torch.save(data, os.path.join(self.processed_dir, f'data_{index}.pt'))\n",
    "\n",
    "    def len(self):\n",
    "        \"\"\"Return the number of graphs in the dataset.\"\"\"\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        \"\"\"Load a graph from disk.\"\"\"\n",
    "        return torch.load(os.path.join(self.processed_dir, f'data_{idx}.pt'), weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear, Dropout\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool as gap, global_max_pool as gmp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Hyperparameters\n",
    "embedding_size = 128\n",
    "dropout_rate = 0.3\n",
    "learning_rate = 0.001\n",
    "patience = 5\n",
    "num_epochs = 100\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self,num_features):\n",
    "        # Init parent\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "\n",
    "        # GCN layers\n",
    "        # self.initial_conv = GCNConv(dataset.num_features, embedding_size) # to translate our node features into the size of the embedding\n",
    "        self.initial_conv = GCNConv(num_features, embedding_size) \n",
    "        self.conv1 = GCNConv(embedding_size, embedding_size)\n",
    "        self.conv2 = GCNConv(embedding_size, embedding_size)\n",
    "        \n",
    "        # pooling layer\n",
    "        #self.pool = TopKPooling(embedding_size, ratio=0.8)\n",
    "        #dropout layer\n",
    "        #self.dropout = Dropout(p=0.2)\n",
    "\n",
    "        # Output layer\n",
    "        self.lin1 = Linear(embedding_size*2, 128) # linear output layer ensures that we get a continuous unbounded output value. It input is the flattened vector (embedding size *2) from the pooling layer (mean and max)\n",
    "        self.lin2 = Linear(128, 128)\n",
    "        self.lin3 = Linear(128, 1)\n",
    "        \n",
    "\n",
    "        self.act1 = torch.nn.ReLU()\n",
    "        self.act2 = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x, edge_index, batch_index):\n",
    "        # First Conv layer\n",
    "        hidden = self.initial_conv(x, edge_index)\n",
    "        hidden = F.relu(hidden)\n",
    "\n",
    "        # Other Conv layers\n",
    "        hidden = self.conv1(hidden, edge_index)\n",
    "        hidden = F.relu(hidden)\n",
    "\n",
    "        hidden = self.conv2(hidden, edge_index)\n",
    "        hidden = F.relu(hidden)\n",
    "        #hidden = self.dropout(hidden)\n",
    "        \n",
    "        # Global Pooling (stack different aggregations)\n",
    "        hidden = torch.cat([gmp(hidden, batch_index), \n",
    "                            gap(hidden, batch_index)], dim=1)\n",
    "        \n",
    "        # Apply a final (linear) classifier.\n",
    "        out = self.lin1(hidden)\n",
    "        out = self.act1(out)\n",
    "        out = self.lin2(out)\n",
    "        out = self.act2(out)\n",
    "        #out = F.dropout(out, p=0.5, training=self.training)\n",
    "        out = self.lin3(out)\n",
    "        out = torch.sigmoid(out)\n",
    "\n",
    "        # return out, hidden\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ireen\\AppData\\Local\\Temp\\ipykernel_27460\\1459365807.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 73\u001b[0m\n\u001b[0;32m     70\u001b[0m processed_data \u001b[38;5;241m=\u001b[39m preprocess_test_cases(test_cases)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Load trained model\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Perform inference\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m testcase \u001b[38;5;129;01min\u001b[39;00m test_cases:\n",
      "Cell \u001b[1;32mIn[9], line 33\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(model_path, num_features, device)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load a trained GCN model.\"\"\"\u001b[39;00m\n\u001b[0;32m     32\u001b[0m model \u001b[38;5;241m=\u001b[39m GCN(num_features)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 33\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     34\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\ireen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:1360\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1358\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1359\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1360\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1361\u001b[0m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1362\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1363\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1364\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1365\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1366\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[0;32m   1368\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ireen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:1848\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[0;32m   1847\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[1;32m-> 1848\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1849\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1851\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
      "File \u001b[1;32mc:\\Users\\ireen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:1812\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m   1810\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1811\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[1;32m-> 1812\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1813\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1814\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1816\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[1;32mc:\\Users\\ireen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:1784\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[1;34m(dtype, numel, key, location)\u001b[0m\n\u001b[0;32m   1779\u001b[0m         storage\u001b[38;5;241m.\u001b[39mbyteswap(dtype)\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[1;32m-> 1784\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1785\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1786\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1787\u001b[0m )\n\u001b[0;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1790\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[1;32mc:\\Users\\ireen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:601\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;124;03mRestores `storage` using a deserializer function registered for the `location`.\u001b[39;00m\n\u001b[0;32m    583\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[38;5;124;03m       all matching ones return `None`.\u001b[39;00m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[1;32m--> 601\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    602\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    603\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\ireen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:539\u001b[0m, in \u001b[0;36m_deserialize\u001b[1;34m(backend_name, obj, location)\u001b[0m\n\u001b[0;32m    537\u001b[0m     backend_name \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_privateuse1_backend_name()\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(backend_name):\n\u001b[1;32m--> 539\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\ireen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:508\u001b[0m, in \u001b[0;36m_validate_device\u001b[1;34m(location, backend_name)\u001b[0m\n\u001b[0;32m    506\u001b[0m     device_index \u001b[38;5;241m=\u001b[39m device\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;28;01mif\u001b[39;00m device\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_available\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m device_module\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m--> 508\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    509\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    510\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice but torch.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.is_available() is False. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    511\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    514\u001b[0m     )\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice_count\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    516\u001b[0m     device_count \u001b[38;5;241m=\u001b[39m device_module\u001b[38;5;241m.\u001b[39mdevice_count()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "class TestCase:\n",
    "    def __init__(self, filename, code, vuln=None):\n",
    "        self.filename = filename\n",
    "        self.code = code\n",
    "        self.vuln = vuln\n",
    "\n",
    "\n",
    "def load_source_code(filepath):\n",
    "    \"\"\"Load source code from a file.\"\"\"\n",
    "    with open(filepath, 'r') as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def create_test_cases():\n",
    "    \"\"\"Create test cases with source code files.\"\"\"\n",
    "    return [\n",
    "        TestCase(filename='clear_area.c', code=load_source_code('Data/nonvuln/no_vuln.c'), vuln=False),\n",
    "        TestCase(filename='cwe_119_1.c', code=load_source_code('Data/vuln/cwe_119_1.c'), vuln=True)\n",
    "    ]\n",
    "\n",
    "\n",
    "def preprocess_test_cases(test_cases):\n",
    "    \"\"\"Preprocess test cases using clang_process.\"\"\"\n",
    "    return {tc.filename: clang_process(tc) for tc in test_cases}\n",
    "\n",
    "\n",
    "def load_model(model_path, num_features, device):\n",
    "    \"\"\"Load a trained GCN model.\"\"\"\n",
    "    model = GCN(num_features).to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_vulnerability(model, data, num_runs=5):\n",
    "    \"\"\"Perform multiple inference runs and measure execution time in milliseconds.\"\"\"\n",
    "    data = data.to(device)\n",
    "    times = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_runs):\n",
    "            start_time = time.time()\n",
    "            output = model(data.x.float(), data.edge_index, data.batch)\n",
    "            end_time = time.time()\n",
    "            times.append((end_time - start_time) * 1000)  # Convert to ms\n",
    "        \n",
    "        probability = output.item()\n",
    "        prediction = int(torch.round(output).item())\n",
    "    \n",
    "    avg_time_ms = sum(times) / num_runs\n",
    "    return probability, prediction, avg_time_ms\n",
    "\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Set device\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Define model parameters\n",
    "    num_features = 2  # Replace with actual number of features\n",
    "    model_path = \"Model/gcn_cwe_119_test_lr_0005_p5_01.pth\"\n",
    "    \n",
    "    # Load test cases\n",
    "    test_cases = create_test_cases()\n",
    "    \n",
    "    # Preprocess source code files\n",
    "    processed_data = preprocess_test_cases(test_cases)\n",
    "    \n",
    "    # Load trained model\n",
    "    model = load_model(model_path, num_features, device)\n",
    "    \n",
    "    # Perform inference\n",
    "    for testcase in test_cases:\n",
    "        prob, pred, avg_time = predict_vulnerability(model, processed_data[testcase.filename])\n",
    "        status = \"Vulnerable\" if pred == 1 else \"Safe\"\n",
    "        print(f\"{testcase.filename} - Probability: {prob:.4f}, Prediction: {status}, Avg Inference Time: {avg_time:.3f} ms\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
